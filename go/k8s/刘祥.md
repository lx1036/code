# 个人介绍
* 姓名：刘祥
* 性别：男
* 出生日期：1991-10-10
* 学位：北京理工大学学士(2008-09 ~ 2012-07)/北京航空航天大学硕士(2012-09 ~ 2015-07)
* 工作经验：7 年
* 毕业时间：2015-07-01
* 联系电话/微信号：13426116367
* 电子邮箱：lx1036@126.com或lx20081036@gmail.com
* 目前职位：奇虎360容器云技术专家
* 技术专栏：https://juejin.cn/user/800100194726088/posts
* 应聘职位：云原生研发工程师(Kubernetes方向)
* K8S证书：CKA 证书

# 工作经历及项目经验

## 北京当当网信息技术有限公司(2015-07 ~ 2016-07)
主要使用PHP语言重构一些老业务代码和迭代业务新功能，主要工作内容包括：
(1)负责当当图书和店铺域的改版和优化，并负责后续版本迭代工作。
(2)负责当当优品馆全面改版项目，对一些老代码进行了重构优化，提高代码可读性。

## RightCapital(2016-07 ~ 2019-07)
参与创业，加入时公司共5个人，北京和纽约办公室各2-3个人。作为全栈工程师参与创业，写后端和前端业务。
主要是用 PHP 语言和 Laravel Web 框架做一款金融软件，面向美国市场。主要工作内容包括：
(1)使用 PHP 框架 Laravel 编写金融软件 RightCapital 后端的 Restful API，并使用 PHPUnit/Mockery 编写单元测试和集成测试。
同时，结合业务需求，对 Laravel 做了很多二次开发，并做成共享私有包，并编写 API 的 Swagger 文档。

(2)使用 Angular 作为前端，Laravel 作为后端，并使用 Ant Design 组件库编写 Admin 后台，供美国客服团队使用。
重写金融软件 RightCapital 前端模块，把其从 Angular.js 重写升级到 Angular 框架。

(3)运维云服务器AWS，搭建一些DevOps软件工具，如Gitlab CI/CD、编写Docker images等等，并使用Terraform/Ansible开发一些提高工作效率的工具等等。

## 奇虎360(2019-08 ~ 至今)
在360技术中台云平台部门负责全公司的 K8S 集群维护，主要工作内容包括：

### (1) 在离线混合部署项目开发
背景：


(1.1) 资源隔离 agent 开发
基于阿里混部内核的 POC 验证测试

超线程干扰问题：早期使用 cpuset 来解决，直接使用 NUMA 的物理核直接物理隔离；


相关经验：对 kubelet CPU 管理，CPU NUMA 机制比较了解


(1.2) pod 调度器 scheduler plugin 自定义开发
内容一：人工智能训练作业需要调度器批量调度 pod，而目前 K8S scheduler 的 plugins 是单个 pod 调度，需要开发一个 batch-pods plugin 来支持一组 pod 批量调度，
并且支持如果 pod 数量满足最小数量就认为该组 pod 可以调度。同时该 plugin 还得支持 namespace 级别自定义 GPU 配额限制去调度(配额限制通过 GPU-Quota CRD 定义，
在 plugin Filter 阶段去根据该 namespace-scoped CR 去做 Filter)。

难点：在 PreFilter/Filter 阶段根据 GPU-Quota CRD 来判断是否还有 GPU resource 余量供该 namespace-scope pod 调度；
结合 K8S Scheduler Framework 的 Permit plugin 机制，在 Permit 阶段判断当前组内的 pods 数量总和是否满足 BatchPod CRD 定义的 minNumber，如果
不满足则放入 WaitingPods 内等待其他兄弟 pods 调度，直到数量总和满足则在该 pod Permit 阶段内放行所有其他兄弟 pods，这样就实现了可以按组级别调度 pods，
这里难点是利用了 K8S Scheduler 的 scheduling cycle 内的 Permit plugin，和 bind cycle 是 goroutine 异步的，且在该 goroutine 内会首先阻塞等待
Permit 的结果是否放行当前 pod 进入下一步 Bind plugin，而我们的 batch-pods plugin 是在 Permit 里做文章。

内容二：混合部署时，需要根据 Node 上给离线 Spark pod 作业分配的自定义资源 colocation/cpu 和 colocation/memory 来调度 colocation-spark plugin。
尽管 K8S Scheduler NodeResourcesFit plugin 默认支持过滤自定义资源，但是我们这里还需要根据策略来过滤，所以需要自定义开发一个 plugin。

难点：这里主要是 pod resource 内有自定义资源，调度器在 PreFilter/Filter plugin 阶段读取 node allocatable 中 colocation/cpu 和 colocation/memory，
并按照不同的策略来选择不同的 ration 比率计算出可被离线 pod 调度的还剩余资源，并进行过滤。而 node allocatable 中 colocation/cpu 和 colocation/memory
是由一个 controller 去 watch NodePolicy CRD 通过计算再去更新 node status 中获得的。plugin 难点不大，比较简单。
同时，还需要开发一个简单的 controller 去更新 node status 中自定义资源 colocation/cpu 和 colocation/memory 的值。

现状：目前少批量 K8S 采用的是我们自研的 Scheduler，所有在线和离线 Pod 都使用这个 Scheduler，缺点是对离线 Pod 调度支持还严重不足。

后期调研：针对人工智能和大数据部门的一些需求和整体规划，针对混合部署的场景需求下，正在调研专门调度离线 pod 的调度器华为开源的 volcano。离线 Pod 使用 volcano 调度，在线 Pod
使用 K8S default Scheduler，但是这会引发多调度器资源冲突问题，目前正在调研相关的解决方案，最好能够做到只使用一个 Scheduler，既可以调度在线 Pod，又可以调度离线 Pod。

相关经验：K8S pod 调度器的内部机制有不错的了解和实践，包括整个 plugin 架构和调度队列数据存储等机制。
对在离线混合部署和大数据上 K8S 有一定的实践经验，尤其是大数据上 K8S 使用到的 spark-operator 等组件源码，都比较了解。

(1.3) 网络带宽隔离和限制相关的调研


### (2) 负载均衡项目 LoadBalancer Operator(依赖外部 LVS)，实现暴露 K8S 集群内 Pod 为集群外提供服务
内容：替换旧的通过 externalIP service 对外暴露服务方式(内部俗称边缘节点方式，与 NodePort 方式类似)，使用 K8S Pod 直连公司已有的生产 LVS (keepalived 搭建)集群方案，
实现集群外部流量由 LVS 集群接管。K8S 集群内部四层负载均衡由 kube-proxy 组件来接管(部分 K8S 由 Cilium eBPF 替换 kube-proxy)，外部由 Cilium+BGP(bird) 来宣告 Pod Cidr。
最终，实现 LVS VIP 直连 PodIP，并结合 BGP 宣告分配给每一个 Node 的 Pod Cidr，使得 PodIP 公司内网可达，实现包从 LVS 集群直接跳转 Pod 所在的 Node，减少网络跳转，提高网络性能，实现了服务对外暴露方式。
初始版本把 LVS 相关配置放入 ClusterIP Service Annotation 里，后续使用 LoadBalancer CRD 模式重构了一版本并生产可用，使得配置更简单，且更具有可观测性。

难点：因为调用 LVS API 更改 LVS 配置后，需要等待 28s 后 LVS 才会下发配置规则，所以在删除 Pod 时，需要在 LVS 侧 RS 被删除之后才能删除 Pod，这里需要
利用 webhook 给 Pod 打上 PreStop lifecycle graceful-shutdown 保证 30s 之后 Pod 才会被删除；
滚动更新在新建 Pod 时，极端情况下 LVS 侧 RS 创建失败，新 Pod 创建成功且 ready，旧 Pod 会批量被删除，导致 LVS 下没有新的 RS 而旧 RS 全部删除，流量严重损失，
所以只有在 LVS 侧 RS 创建成功时才会使得 Pod 为 ready 状态，再依次滚动下一个 Pod，所以利用 webhook 给 Pod 打上一个自定义的 ReadinessGate，RS 创建成功后再使能 Pod 为 ready 状态；
LVS 侧不稳定，调用删除 RS API 28s 后 RS 规则还存在，而此时 Pod 已经删除，导致流量丢失，webhook 会拦截删除 Pod 请求并先去 LVS 侧做检查，缓解此类极端情况，同时周期性去同步
LVS 侧 RS 和 K8S 侧的 Pod 列表来进一步缓解此类极端情况；

现状：大多数生产 K8S 集群已经使用该方案作为暴露 Pod 服务的优先方案。

### (3) 负载均衡项目 LoadBalancer Operator(不依赖外部 LVS)，实现暴露 K8S 集群内 Pod 为集群外提供服务
背景：LVS 集群不稳定尤其性能原因(RS数量过大后 keepalived 配置更新容易失败导致应该删除的 RS 没有删除等问题，造成流量丢失，目前临时解决方案是 LVS 定期重启)，
以及 to B 交付时无法交付 LVS 套件(目前只有 NodePort 方案)，所以必须探索出一套不依赖于外部 LVS 的暴露服务的方案。
公司内使用作为 LoadBalancer Operator(依赖外部 LVS) 方案的补充，公司外交付时的另一种方案选项。

内容：替换 LoadBalancer Operator(依赖外部 LVS)方案，借助 K8S 集群内已经实现了四层负载均衡的机制，和 K8S LoadBalancer Service 机制，开发
K8S LoadBalancer Service IPAM Operator (Deployment 部署)来给 LoadBalancer Service 分配 ServiceIP，且支持多个 ServiceIPPool 以及指定特定的 ServiceIPPool。

同时为了使得该 ServiceIP 也在集群外可达，开发 LoadBalancer Service BGP Speaker 宣告 ServiceIP(Daemonset 部署)，且通过 BGPPeer CRD 配置，
使得 LoadBalancer ServiceIP 在集群外可达，可以不再依赖外部 LVS 集群，且网络跳转数量更少，性能更高。并且支持 Service ExternalTrafficPolicy 功能。

同时为了替换 K8S 集群内部署的 bird Daemonset 软件来宣告 Cilium Operator 给每一个 Node 分配的 Pod Cidr，因此开发了 Pod Cidr BGP Speaker 来宣告，使得 PodIP 在集群外可达，目前已经在部分生产 K8S 集群上线。

该方案相比于 LoadBalancer Operator(依赖外部 LVS) 优点：不再依赖于外部 LVS 集群，交付更简单；网络跳转更少，性能更高；
Pod 滚动时为了减少流量丢失，依赖外部 LVS 方案使用了 ReadinessGate 等一系列缓解方案，而本方案则把 Pod 滚动交给了 kube-proxy 或 Cilium 去解决，不存在流量丢失问题。
该方案相比于 LoadBalancer Operator(依赖外部 LVS) 缺点：依赖 BGP 宣告路由，且每一个 ServiceIP 对应多个 Node 的路由，导致上层交换机路由数量会变大。

现状：公司内部作为 LoadBalancer Operator(依赖外部 LVS) 方案的补充使用，公司外部交付优先考虑的方案。

### (4) Cilium IPAM Operator 项目
内容：针对 K8S 集群内需要根据 nodeSelector 选择不同的 IPPool 需求，比如集群内有些 worker nodes 是专属某个业务的，且该业务因为调用外部服务需要使用另一个 pod cidr。
并且尽可能需要一个 Node 可以配置多个 PodCidr，实现当 Node 的 IP 资源不足时，可以动态扩容 IP，该需求类似于 Calico 支持多个 IPPool 功能，且公司业务需要该功能。

难点：但是 Cilium 目前不内置支持根据 nodeSelector 选择不同的 IPPool 需求，且无法支持一个 Node 可以配置多个 PodCidr，需要根据 Cilium IPAM 自定义开发。
目前已经根据两种不同的 Cilium IPAM 分别开发了对应的 Operator。

#### Cilium Kubernetes IPAM Operator
根据 Cilium Kubernetes IPAM 机制开发自定义的 Operator，结合 cilium-agent 从 K8S Node 或 Node Annotation 中读取 PodCidr 机制，所以选择
关闭 kube-controller-manager 给 K8S Node 分配 PodCidr，开发自定义 Operator 来根据 Node Labels 选择不同的 IPPool 并分配对应的 PodCidr，并添加到
Node Annotation 中，从而实现了不同 K8S Node 可以选择不同的 IPPool 需求。

总之，目前已经生产可用，经过一段时间使用，符合业务需要，且不需要更改 cilium-agent 以及 BGP 相关的配置参数。

#### Cilium CRD IPAM Operator
更进一步，第一种方案尽管已经满足业务需要，但是该方案不支持一个 Node 配置多个 PodCidr，而资源更大的 Node 支持更多 PodIP，
所以更进一步，选择 Cilium CRD IPAM 机制，再次开发自定义的 Operator，支持按需动态扩容和回收节点的 PodCidr IP 资源。

在 Cilium CRD IPAM 模式下，CiliumNode 存储的是一个个可以被分配出去的 IP，可以在这里设计这些 IP 来自于多个 PodCidr，从而实现了一个 Node 支持多个 PodCidr。
同时为了保证这多个 PodCidr 被宣告出去，还得更改 BGP speaker，以及 cilium-agent 的一些默认行为(通过更改 Cilium 配置参数来实现)。

缺点：该方案实现复杂，同时需要更改 cilium-agent 相关参数，比如 cilium-agent 默认只会为有且仅有一个 PodCidr 创建一个路由指向网卡 cilium_host，为了支持多个 PodCidr，
需要开启每一个 Pod 一个路由的配置参数，而出于性能考虑这不是 Cilium 的默认行为，等等几个其他参数配置；同时还需要修改 BGP speaker 软件 bird 的配置。

总之，该方案有点 hack。总之，出于稳定性考虑以及业务需要考虑，暂时在测试 K8S 集群部署使用。

现状：出于稳定考虑，目前生产 K8S 先小批量使用 Cilium Kubernetes IPAM Operator，后续再考虑使用 Cilium CRD IPAM Operator。


### (5) 自定义容器网络插件 VPC-CNI 项目
#### (5.1) VPC-CNI
背景：由于网络部门决定后续公司内交换机不再支持 BGP(由于 BGP 路由太多导致很多维护问题)，以及容器网络需要和虚拟化团队提供的 VPC 网络相融合，部门从上而下开始推动
容器网络逐渐向 VPC 网络靠拢，需要容器网络和 VPC 网络在同一个网络平面，需要容器团队提供相应的解决方案。

内容：解决方案是利用虚拟机弹性网卡绑定多 IP 机制，来打通容器网络平面和虚拟机网络平面，即调用 VM API 给该 VM 创建挂载一个新的弹性网卡，并绑定多个 IP 给 Pod 使用，
这些 IP 是和虚机 IP 在同一个 VPC 网段内，这样就实现了集群内同 Node 和跨 Node 的 Pod 相互通信，以及集群外访问 PodIP 通信问题，访问 PodIP 和访问 VM IP 没有任何区别。
整个过程无需 BGP 去宣告路由，且不存在不同规格 Node PodIP 资源浪费问题。且和 VPC 网络完全融合，容器团队无需再和网络部门沟通网络问题，VPC 网络问题都交给虚拟化团队去负责。

针对容器上虚机场景，需要开发 CNI Bin 组件和 IPAM Daemon 组件。
* Bin 组件 grpc 调用 IPAM Daemon 组件获取 PodIP，并创建 ipvlan 网卡 eth0 置于 Pod 内，该 eth0 的 parent 网卡是弹性网卡，采用 ipvlan L2 mode，即弹性网卡作为二层网桥。
并配置 PodIP 到 eth0 网卡上，配置默认路由(出口网卡是eth0，网关地址是弹性网卡的网关地址)，以及机器的 nodeIP 对应的 eth0 mac 的 arp 表。
同时为了 serviceCidr

难点：

不足：还没有实现基于 pod 的 ingress/egress 网络带宽限制 bandwidth，



使用 ipvlan 技术连通不同 namespace 的容器，开发 CNI。

#### (5.2) CNI NetworkPolicy
同时使用 iptables/ipset/conntrack 技术基本实现了 NetworkPolicy 功能，包括：。

目前正在调研把 Cilium 作为 NetworkPolicy 组件来部署，无需再开发 NetworkPolicy Controller。

### (6) fusefs-csi 和 fusefs 项目

#### (6.1) 开发 fusefs 分布式文件系统项目：fusefs 项目包含 fuse-client、master(raft) 和 meta-partition(multi-raft) 三个模块
fusefs 项目的三个模块：部署时 master 作为控制平面一般部署3节点，使用raft保证数据强一致性；meta-partition 节点可以无限扩展，每个 meta partition 默认3节点，使用 multi-raft 保证数据强一致性；
fuse-client 进程置于 fusefs-CSI Pod 里，每个 k8s worker node 上每个 pv(可以被多个 pod 挂载) 启动一个 fuse-client 进程来实现 fuse 挂载。 

(1)主要参与开发 fuse-client 模块，使用 fuse 实现本地化直接读写文件，数据存储在远程 S3 上。inode 和 dentry 数据结构都缓存在本地内存中，
其中 inode 使用 LRU 数据结构存储，根据其有效时间来从 meta-partition 刷新 inode。并且修改第三方 fuse 包，使其支持 macOS 系统，使得可以 mac 本地运行。

(2)主要参与开发 master 模块，主要提供 meta node 注册相关 api；create/delete volume 等相关 api 被 fusefs-csi 调用，
并在 volume 创建时根据 meta node 使用率选择对应数量的 meta node，在每一个 meta node 上创建包含 inode 范围的 meta partition 数据。
使用 raft 来实现数据强一致性，raft log 和相关 term 等配置数据，存储在 boltdb 中。通过定期 raft snapshot 实现状态机的快照，
状态机数据比如 volume 及其相关的 meta partition 等数据，也是持久化到 boltdb 中。所以，有两个 boltdb 文件，一个持久化 raft log 和 raft 配置数据，一个是持久化状态机数据。

(3)部分参与 meta-partition 模块，该模块主要管理 inode/dentry 元数据。每一组 meta partition 由 raft 保证强一致性，多组 meta partition 组成
raft group。对于每一组 raft meta partition，其状态机由两个 B-Tree 分别创建和删除 inode/dentry。

#### (6.2) 开发 fusefs-csi 项目：为团队自研的分布式文件存储实现一个 K8S CSI，方便业务 pod 动态挂载 fusefs pvc
内容：独立开发整个 CSI 项目。CSI 实现了 ControllerServer service 接口，当用户创建 pvc 时，PVController 通过给 pvc 打 annotation 和 
external-provisioner sidecar 容器交互，然后该容器作为 csi client 调用 CreateVolume/DeleteVolume/ExpandVolume 等 ControllerServer service 接口，在
这些接口中会调用 fusefs master 组件提供的 HTTP API；同时，CSI 也实现了 NodeServer service 接口的 NodeStageVolume/NodePublishVolume 等接口， 
这里利用了 NodeStageVolume 接口解决了当同一个节点调度多个 pod 相同副本时，只会在该节点内启动一个 fuse-client 进程，从而提高了资源利用率，
在第一个 pod 副本调度到这个节点时，会启动有且仅有一个 fuse-client 进程，后续 pod 副本不会启动，fuse-client 进程挂载点为一个全局挂载点 xxx/pv/pvID/globalmount，
然后在 NodePublishVolume 接口内为每一个 pod 去做 bind mount 到 pod 的挂载点 xxx/pods/podID/mount。
这里利用了 kubelet 的块存储设计机制：在调用相同 pod 的多个副本时，第一个 pod 会调用 NodeStageVolume 和 NodePublishVolume，但是随后的 pod 副本不会调用 NodeStageVolume，而只会调用 NodePublishVolume。

难点：由于 fuse-client 在 CSI Pod 内启动形成的紧耦合，如果 CSI Pod 由于升级导致的重建，导致业务 pod 的挂载点损坏，业务 pod 基本不可用的严重副作用，只有业务 pod 重新滚动才能解决此类问题。
社区内类似这种 fusefs csi 都有这种问题，而大多数 csi 并没有很好的解决此类问题，只能寄希望于 CSI Pod 永不重建。

但是，我的解决方案完美解决了社区 fuse 分布式文件系统共有难题：CSI Pod 重启，业务 Pod 挂载点损坏，导致业务 Pod 无法读写数据。解决方案为两种：

(1)CSI Pod 重启后，需要加上 fuse recovery 机制，根据 K8s VolumeAttachment 对象获取所有相关数据，再在 CSI Pod 内重启 fusefs-client 进程(该方案已经回馈给京东 cubefs-csi 社区)。
等 CSI Pod 重建完成，业务 Pod 可以继续多写数据而不用重建，而该方案之前却是业务 Pod 一直不可用只能重启才可以(生产环境不现实)，这大大减缓了业务 Pod 使用 PVC 的痛点。
但是该方案有些瑕疵，在 CSI Pod 重建的几十秒时间内，挂载点依然是坏的，业务 Pod 依然不可读写 PVC 数据，尽管只有几十秒时间不可用，远比之前的一直不可用已经大大进步。

(2)使 fuse-client 进程完全独立于 CSI Pod，单独作为 Fuse Pod 运行实现解耦，CSI Pod 作为控制平面来 create/delete Fuse Pod，并结合 CSI NodeStageVolume/NodeUnstageVolume 
和 NodePublishVolume/NodeUnpublishVolume 机制实现代码简洁化。同理，在 NodeStageVolume/NodeUnstageVolume 接口内去 create/delete fuse Deployment，在
NodePublishVolume/NodeUnpublishVolume 去做 bind mount 全局挂载点到每一个 pod 的挂载点。(已经向 cubefs-csi 和 juicefs-csi 社区反馈)

后续：独立调研 eBPF 在 linux 磁盘 I/O 上的性能优化，包括把 fuse 用户态的一些接口对应的业务逻辑下沉到内核层去执行，无需再从内核态到用户态的一次数据复制，从而达到更高性能。
调研发现社区内已经有相关的尝试和文档，不过还不成熟，且貌似还需要修改 linux 文件系统相关代码，重新编译 linux 内核(存疑)。总之，由于时间精力有限，无法继续深入调研。

相关经验：对 K8S CSI 内部机制和源码都比较了解，包括 kubelet 中的 csi volume 机制以及相关 sidecar 容器内部机制，对 StorageClass 的 Immediate 立即绑定和 
WaitForFirstConsumer 延迟绑定 pv 的内部机制都比较了解，总之对 CSI 相关开发经验比较了解。了解 raft 共识算法内部机制和 linux vfs fuse 机制，以及分布式文件存储内部机制。

### (7) log-operator 以及 filebeat processor 二次开发
基于公司内搜索部门的特殊需求，二次开发一个 filebeat processor 插件，并编译进 filebeat 源码内作为公司内部维护版本。
同时为支持

并对 filebeat 源码和运行机制有一定了解。


### (8) 废弃的项目
在调研和开发后期，由于不可抗力因素导致的废弃项目：
* etcd-operator etcd 中间件上 K8S 项目：对 etcd 机制和内部原理比较了解，包括对 raft 和 mvcc 的了解。
* 大数据上 K8S 项目：涉及到的技术栈 spark-operator 和 volcano，对 spark-operator 源码比较熟悉，对 volcano 源码有所了解。

# 个人描述
做事情认真负责，喜欢团队合作。
对云原生感兴趣，主要关注 kubernetes 生态相关技术，包括但不限于网络、分布式存储、监控、日志和网关相关技术。对 eBPF 应用于容器网络和可观测性比较感兴趣。





# 面试

## 数据结构和算法
(1)fusefs-client 中的 LRU(哈希表和双向链表)
(2)fusefs meta-node 中的 b-tree，以及 b+tree
(3)优先级队列(平衡树、最小堆、最大堆)

(4)单向链表和双向链表
单链表反转，

(5)二叉树

(6)LRU数据结构
