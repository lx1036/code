

各个公司面试题：https://github.com/0voice/interview_internal_reference


# 算法(公司面试题)
大数相加: https://leetcode-cn.com/problems/add-strings/
最长上升子序列: https://leetcode-cn.com/problems/longest-increasing-subsequence/
下一个排列: https://leetcode-cn.com/problems/next-permutation/

1. 有一个已经排好序的数组，拿一个数字，来在该数组中寻找该数字，该怎么寻找？
   二分法

2. 算法题：求最长的连续回文子串

3. 求二叉树所有路径中，最长连续的自然数序列
   例如：
   1
   2 2
   7 9 8 3
   1 2 2 3 3 4 3 3
   结果是3（1,2,3,3这条路径的1，2,3是满足条件的序列）
   改进：
   要求代码是线程安全的
   变体
   如果不是二叉树，是一个图，代码怎么改（仍然要手写）

4. 算法题：最长连续自然数序列的长度，例如253498，总共有两个连续自然数序列（2345,89），结果为4

5. 算法题：求两条链表第一个相交的节点，不相交输出NULL，第一条链表长m，第二条长n
   要求：时间O(n+m),空间O(1)

判断两个链表有没有相交？相交点怎么获取？

算法题，两个有序链表排序
变体：如果是n个链表呢
还是每次都比较n个链表，然后找出最小值，串起来


给栈实现一个 最小函数

LRU实现

算法题: 有一个int型数组，假设是1,3,4,2,5,7,9。要求对它进行重新排列，最后的数组的的格式是：每一个元素，比它前一个元素和后一个元素都大，或者都小。例如1,3,4,2,5,7,9。最后的形式是：1,5,2,7,3,9,4。
要求：时间O(n)，空间O(n)
思路：快排的变体，先找到数组中的第n/2大元素,这样就将数组分为两部分，第一部分都是小于4，第二部分都是大于4。然后每次从第一部分取一个数，然后再从第二部分取一个数即可。

求两个字符串的最长公共子串

手写快排

(商汤)从一段无序数组到有序数组，返回需要调整区间的大小

旋转数组的二分查找?


# 容器云

1. docker的CPU限制？cgroups怎么做的？
   docker的底层（namespace， cgroup），有哪些namespace
   用Docker如何制作镜像，docker镜像的构建方法？


3. docker网络通信机制？docker底层有哪几种网络通信方式？

4. VPC是啥，讲下原理？

5. 数据库有一张大表，怎么高效访问，聊索引？page是干啥的？inode是干啥的？

6. 进程访问文件的过程？

1. k8s在client访问的时候，如何知道三个Master中哪个是主节点？

2. 说一下k8s调度器的原理？说一下K8S调度器源码是如何实现的？


4. 两个节点的Pod是如何进行通信的？同一个Pod的多个容器可以在不同节点上吗？


说说deployment？说说有状态服务？


画k8s框架图，组件怎么通信？K8s有哪些对象资源，有什么用？


讲一下看过的K8s源码？


K8s创建job的整个过程？

docker的底层实现？cgroup, namespace能不能具体讲讲，源代码有没有读过？


kubelet,apiserver的源代码有没有了解过，有没有改过k8s代码


(美团)讲一下etcd raft算法是怎么实现的？
讨论了raft协议，以及raft协议如何保证一致性，和安全性，比如某个节点挂了。
etcd 投票竞选，日志复制，读写流程，日志压缩，快照?


k8s中pod如何跨节点通信，calico通信机制？

(商汤)raft中网络分区怎么办，会出现数据不一致吗？



做过k8s是吧，来说一下k8s的架构，
（apiserver所有请求入口，以及跟其他组件交互同步资源，list-watch组件间通信，etcd存元数据，kube-proxy DNAT，scheduler预选过滤打分绑定等等）

你刚才说了组件间用list-watch是吧，说一下实现（client-go里边的sharedinformer以及回调）
list-watch机制实现原理

watch底层用的http的什么机制

deployment和statefulset啥区别（有状态应用无状态应用使用场景，pod名字）

k8s高可用怎么做的？

(pingcap面试题)对 Kubernetes 了解怎么样，看过源码吗？

对iptables的一些理解，iptables 四表五链工作原理，DNAT发生在哪条链？

容器与宿主机一个网段该怎么实现？（我目前只知道docker的none模式，然后自己使用ip link等命令搞一堆虚拟设备）
cidr写成宿主机网段。



kube-scheduler调度机制
https://github.com/kubernetes/community/blob/master/contributors/devel/sig-scheduling/scheduler.md
https://www.bookstack.cn/read/source-code-reading-notes/kubernetes-kube_scheduler_process.md


(pingcap面试题)informer是怎么实现的，有什么作用？
参考：
使用 Clientset 获取 Kubernetes 资源对象: https://mp.weixin.qq.com/s?__biz=MzU4MjQ0MTU4Ng==&mid=2247485559&idx=1&sn=ccfa27d3688bf6384a7a5f28ed76eecd&chksm=fdb9076acace8e7cdcfab689f5791b42374ca0881d476937dd29553fd63c7d9729d468ee3c3b&scene=21#wechat_redirect
client-go连接K8s集群进行pod的增删改查: https://mp.weixin.qq.com/s/pis0FDjTaLDxtMyz8VWlRQ
Kubernetes 中 Informer 的使用: https://mp.weixin.qq.com/s?__biz=MzU4MjQ0MTU4Ng==&mid=2247485580&idx=1&sn=7392dbadff9ab450d93c5dd0449dace5&chksm=fdb90791cace8e871b1dcdd00be21f16a23504f48634f4fb7d3c87a552b3f8ce2765862fb4e9&scene=21#wechat_redirect
client-go 之 Reflector 源码分析: https://mp.weixin.qq.com/s?__biz=MzU4MjQ0MTU4Ng==&mid=2247485777&idx=1&sn=1bafe2c077f903e78997e9a33a8fc768&chksm=fdb9064ccace8f5a28f14c1c0ada0a52bae72d7b397c30737d08e4a7db23e21549a2c2d7cd58&scene=21#wechat_redirect
client-go 之 DeltaFIFO 实现原理: https://mp.weixin.qq.com/s?__biz=MzU4MjQ0MTU4Ng==&mid=2247485864&idx=1&sn=2011dfed276fe75a767d1e55f7d979ce&chksm=fdb906b5cace8fa3a01b911ac1004f6d6b57d8e0ae0d9a0e0746cdfa988947cc0e37ad2a980c&scene=21#wechat_redirect
client-go 之 Indexer 的理解: https://mp.weixin.qq.com/s/xCa6yZTk0X76IZhOx6IbHQ

Client-go之Informer机制初探: https://mp.weixin.qq.com/s/zXXKrk-juZWJhzNSYBVK_w
Client-go Informer之 DeltaFIFO队列: https://mp.weixin.qq.com/s/sCpuCHRGQYyv8VQodW0dTw
Client-go之Informer机制之本地存储Indexer: https://mp.weixin.qq.com/s/VmL8rw87YBoKnb_t3L4nXw
Kubernetes Informer 机制源码解析: https://mp.weixin.qq.com/s/f-KNM9AtBGGVWhrNmwa2JA


(pingcap面试题)statefulset有什么特点？statefulset滚动升级是如何实现的？现在我们希望只是升级statefulset的任意一个节点进行测试，怎么做？
正确方法是利用partition机制来做节点测试。

(pingcap面试题)k8s所有资源约定了版本号，为什么要这么做？如果多个版本号存在，那么k8s需要维护几套代码么？
这里好像是k8s内部会转换版本号，有个内部统一版本。
或许通过研究client-go包的client可以知道原因，以及内部代码怎么转换版本的: https://mp.weixin.qq.com/s/pis0FDjTaLDxtMyz8VWlRQ



kubelet要创建一个容器的具体过程？
https://mp.weixin.qq.com/s/_NJA71eWT0-mGEMy1DEqLw
1. Kubelet 通过 CRI 接口（gRPC）调用 dockershim，请求创建一个容器。
CRI 即容器运行时接口（Container Runtime Interface），这一步中，Kubelet 可以视作一个简单的 CRI Client，而 dockershim 就是接收请求的 Server。
目前 dockershim 的代码其实是内嵌在 Kubelet 中的，所以接收调用的凑巧就是 Kubelet 进程；
2. dockershim 收到请求后，转化成 Docker Daemon 能听懂的请求，发到 Docker Daemon 上请求创建一个容器。
3. Docker Daemon 早在 1.12 版本中就已经将针对容器的操作移到另一个守护进程——containerd 中了，因此 Docker Daemon 仍然不能帮我们创建容器，而是要请求 containerd 创建一个容器；
4. containerd 收到请求后，并不会自己直接去操作容器，而是创建一个叫做 containerd-shim 的进程，让 containerd-shim 去操作容器。这是因为容器进程需要一个父进程来做诸如收集状态，维持 stdin 等 fd 打开等工作。
   而假如这个父进程就是 containerd，那每次 containerd 挂掉或升级，整个宿主机上所有的容器都得退出了。而引入了 containerd-shim 就规避了这个问题（containerd 和 shim 并不是父子进程关系）；
5. 我们知道创建容器需要做一些设置 namespaces 和 cgroups，挂载 root filesystem 等等操作，而这些事该怎么做已经有了公开的规范了，那就是 OCI（Open Container Initiative，开放容器标准）。
   它的一个参考实现叫做 runC。于是，containerd-shim 在这一步需要调用 runC 这个命令行工具，来启动容器；
6. runC 启动完容器后本身会直接退出，containerd-shim 则会成为容器进程的父进程，负责收集容器进程的状态，上报给 containerd，并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理，确保不会出现僵尸进程。


(pingcap面试题)k8s service是什么，怎么实现的?


k8s 存储架构，以及storageclass动态创建pv的存储交互流程？



###(Docker容器网络通信)Docker不同容器间如何通信?Docker网络模型?
docker网络驱动：bridge,host,none,plugins(如calico)
veth pair+linux bridge实现同一主机上不同容器间通信。


###什么是BGP、IBGP和EBGP?
边界路由器VBR(virtual border router)作为数据从VPC到本地数据中心的桥梁，可以管理路由表，支持BGP。
BGP(border gateway protocol)是一种基于TCP协议的动态路由协议，主要用于不同自治域AS(Autonomous system)间交换路由信息和网络可达信息。
EBGP和IBGP都遵循BGP协议，它们的工作流程，处理方式，甚至核心程序，都是一样的。区别在于一些细节参数，默认行为不同：
EBGP用来连接各个AS，AS之间的连接协议，目前在用的，有且仅有EBGP一种。
IBGP应用在AS内部，对于路由器来说，EBGP和IBGP只是对应的参数不太一样，但都是通过一个BGP进程来运行，这不会增加路由器的负担。


# golang



# 基础题















# Kubernetes

## 第一阶段：基本知识
(1) 什么是 Kubernetes ？容器编排的价值和好处是什么？容器和主机部署应用的区别是什么？



## 第二阶段：技术细节
(1) Kubernetes 有哪些组件？

(2) 如何在 Kubernetes 中实现负载均衡？在生产中，你如何实现 Kubernetes 自动化？你如何扩展 Kubernetes 集群？


(3)你能解释 Deployment、ReplicaSets、StatefulSets、Pod、CronJob 的不同用途吗？
Kubernetes 如何处理持久性？服务和 ingress 的作用是什么？你何时会使用像 ConfigMap 或 secret 这样的东西？
Pod 亲和性作用是什么？你能举例说明何时使用 Init Container 么？
什么是 sidecar 容器？你能给出一个用例，说明你为什么要使用它么？


## 第三阶段：生产经验
(1) 在构建和管理生产集群时遇到的主要问题是什么？



## 第四阶段：K8S 的使用目的
(1) 什么是 Kubernetes Operator？


(2) 你对Kube-proxy有什么了解？


(3)kube-apiserver和kube-scheduler的作用是什么？
kube -apiserver遵循横向扩展架构，是主节点控制面板的前端。这将公开Kubernetes主节点组件的所有API，并负责在Kubernetes节点和Kubernetes主组件之间建立通信。
kube-scheduler负责工作节点上工作负载的分配和管理。因此，它根据资源需求选择最合适的节点来运行未调度的pod，并跟踪资源利用率。它确保不在已满的节点上调度工作负载。

(4) 你能简要介绍一下Kubernetes控制管理器吗？
多个控制器进程在主节点上运行，但是一起编译为单个进程运行，即Kubernetes控制器管理器。
因此，Controller Manager是一个嵌入控制器并执行命名空间创建和垃圾收集的守护程序。它拥有责任并与API服务器通信以管理端点。
node-controller,replication-controller,endpoint-controller,service-account/token controller

(5) 什么是ETCD？
Etcd是用Go编程语言编写的，是一个分布式键值存储，用于协调分布式工作。因此，Etcd存储Kubernetes集群的配置数据，表示在任何给定时间点的集群状态。

你对Kubernetes的负载均衡器有什么了解？
负载均衡器是暴露服务的最常见和标准方式之一。根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。
内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器。

什么是Ingress网络，它是如何工作的？

业务目前使用 k8s的遇到的一些问题，遇到过 k8s 的一些 bug 怎么解决的，改造过 k8s 么为啥要改造，这些问题提前想想？


k8s 周边的一些东西也尽量了解一下，knative、argo、kubeflow、virtualkubelet？



########重点#######################
# K8s是如何实现负载均衡的？

# K8s负载均衡(Service四层/Ingress七层)
浅谈Kubernetes Service负载均衡实现机制: https://xigang.github.io/2019/07/21/kubernetes-service/
Kube-Proxy IPVS模式源码分析: https://xigang.github.io/2019/07/28/kube-proxy-source-code/
华为云在 K8S 大规模场景下的 Service 性能优化实践: https://zhuanlan.zhihu.com/p/37230013
K8s Service有哪些，以及kube-proxy如何实现service四层负载均衡？
service types: ClusterIP, NodePort, LoadBalancer, Ingress(七层)
kube-proxy以daemonset形式运行在每一个node上，会watch api-server上的service和endpoint资源对象；当创建一个service后，每一个kube-proxy会调用
iptables或ipvs客户端来创建路由规则，主要是nat表内的规则，会在kube-services chain 上创建路由规则，tcp流量根据cluster ip一步步跳转到对应的pod ip，然后
从该节点出去，下一跳是pod ip；

kube-proxy工作原理?







# 与k8s api-server通信的list-watch机制和informer模块的工作原理?
**灵感来自 https://zhuanlan.zhihu.com/p/59660536**
其实就是消息生产者和消费者模型：
(1)生产者ListAndWatch api-server: Reflector对象作为生产者，首先会List()特定资源，然后会Watch()该特定的资源，比如pod资源，这样对于以后每次pod资源的任何事件，比如
CreateEvent/UpdateEvent/DeleteEvent，这些称为ResourceEvent对象如{type: "Added", object: &Pod{},}，Reflector会把这些ResourceEvent对象
存入Store对象中。这里，Reflector对象作为生成者，Store对象作为消息队列，存储ResourceEvent对象。
这里Watch()特定资源意思是：api-server会主动把每次ResourceEvent发给客户端，这里使用HTTP/1.1长链接并分块传输编码实现的，response headers里包含 Transfer-Encoding: chunked，这样
客户端和api-server保持长链接，api-server只要有pod资源的ResourceEvent发生，就会持续不断分块传输ResourceEvent。实现了服务端主动push数据给客户端。
(2)消息队列: DeltaFIFO Queue作为消息队列数据结构，就是一个很关键的Store对象，且是并发安全的一个queue，来存储ResourceEvent。
(3)消费者：Controller对象，作为消费者使用DeltaFIFO.Pop()来消费ResourceEvent，获取该ResourceEvent对象。
(4)Informer: 总体封装对象，包含Store和Controller对象，以及最重要的ResourceEventHandler对象，这是一个interface，
该interface包含的onAdd()/onUpdate()/onDelete()操作方法，具体操作由开发者去定义，且用户定义的都是写操作，比如：
```go
import (
 "k8s.io/client-go/tools/cache"
)
podGenericInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
    AddFunc: func(obj interface{}) {

    },
    UpdateFunc: func(old, new interface{}) {
    
    },
    DeleteFunc: func(obj interface{}) {
    
    },
})
```
(5)读操作：同时Informer包含一个Indexer对象，即Store对象，也就是threadSafeMap对象，在controller作为消费者去DeltaFIFO queue当中取ResourceEvent时，
同时也会将该对象存入threadSafeMap对象中，这样读操作会直接从threadSafeMap对象中去取。

# 使用controller-runtime pkg写operator以及controller-runtime工作原理?




# k8s负载均衡几种形式和工作原理?
k8s负载均衡包括四层service和七层ingress:
service类型包含ClusterIP、NodePort和LoadBalancer:
(1)k8s主要使用kube-proxy组件作为DaemonSet部署在每一个node上，根据启动参数mode不同，要么使用iptables模式或者ipvs模式，来在内核层设置流量包的路由规则。
kube-proxy组件会watch api-server上的service和endpoint资源对象，当创建一个service后，每一个kube-proxy会调用iptables或ipvs客户端来创建路由规则，
主要是nat表内的规则，会在kube-services chain上创建路由规则，tcp流量根据cluster ip一步步跳转，再跳转到kube-sep chain上，最后到对应的pod ip，然后从该节点出去，下一跳是pod ip。其中，ipvs作用在
input chain，而不是像iptables作用在prerouting chain，所以ipvs模式需要给该vip在本机设置个虚拟网卡。
而且，与iptables作为防火墙功能不一样，ipvs本身就是作为负载均衡功能，支持多达八种左右负载均衡算法，如最小链接、轮询、权重等等。
且iptables使用链表存储路由规则，ipvs使用哈希表存储，这样流量包在查找下一跳规则时效率更高，减少流量包延迟。
(2)流量包出node下一跳是pod ip，如果使用calico网络插件，则使用的是路由转发，会找到路由规则即pod ip在这个IP段内请跳转到该node ip上，这些路由规则动态更新是calico felix做的，
路由规则广播是calico bird做的。从而实现了跨node的pod之间相互通信。
(3)流量暴露三种方式：
带有ExternalIPs ClusterIP Service，边缘节点形式，选择几个node节点作为边缘节点，然后再用个vip下rs挂载这些node节点，业务直接vip:port对外暴露；
NodePort Service，port成为node节点的port，类似docker里host network形式，这样每一个node都会开这个port，没有边缘节点形式友好，只会有几个node开port；
自研LoadBalancer直连Pod IP(lvs vip的rs为pod ip)，使用kubebuilder工具自定义crd，编写cr设置业务的deployment/service，然后watch deployment，只要该
deployment在你的cr里，就通过service获取endpoint对象，进而获取所有pod ips，然后调用lvs api获取该vip下所有的pod ips，进行diff，有修改则调用add/delete lvs api去更新
lvs下的pod ips，整个过程也就是reconcile，最终达到lvs vip下pod ips期望值和实际业务pod ips保持同步；

nginx-ingress:
nginx-ingress主要目标是构建nginx.conf文件，并负责当nginx.conf文件变化时去reload nginx，但是当upstream里指向的endpoints变化时，不会reload nginx。
(1)使用了nginx反向代理到upstream模块实现七层的负载均衡，upstream指向的是service下的多个endpoints，且具有服务发现功能。
但是，当endpoints随着业务发布而变化时，因为upstream里用的balancer_by_lua_block()函数，endpoint对象从lua变量读取的，所以并不会重启nginx进程。
(2)流量暴露：
nginx-ingress部署在指定node节点上，并挂载在某vip下，业务可以根据host域名来反向代理到不同的upstream上。
ingress里定义的每一个业务在nginx.conf里就是一个server模块，path是server下的location模块。可以通过docker cp命令把容器内的nginx.conf拷贝出来分析分析。



# etcd基本架构以及数据持久化原理?



